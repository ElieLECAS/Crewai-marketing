from crewai_tools import SerperDevTool, WebsiteSearchTool, ScrapeWebsiteTool, PDFSearchTool, RagTool
from crewai.knowledge.source.pdf_knowledge_source import PDFKnowledgeSource
from typing import List, Dict, Any
import os

def get_available_tools() -> Dict[str, Any]:
    """Retourne la liste des outils disponibles avec leurs configurations"""
    tools = {}
    
    # Serper pour recherche web
    if os.getenv("SERPER_API_KEY"):
        tools["serper_search"] = {
            "name": "Recherche Web (Serper)",
            "description": "Recherche d'informations sur le web via Serper",
            "tool": SerperDevTool(),
            "enabled": True
        }
    
    # Recherche sur site web
    tools["website_search"] = {
        "name": "Recherche sur Site Web",
        "description": "Recherche dans le contenu d'un site web sp√©cifique",
        "tool": WebsiteSearchTool(),
        "enabled": True
    }
    
    # Scraping de site web
    tools["scrape_website"] = {
        "name": "Scraping de Site Web",
        "description": "Extraction du contenu d'une page web",
        "tool": ScrapeWebsiteTool(),
        "enabled": True
    }
    
    # Outils PDF et RAG (CrewAI natifs)
    tools["pdf_search"] = {
        "name": "Recherche PDF (CrewAI)",
        "description": "Recherche s√©mantique dans les fichiers PDF via CrewAI. Les PDFs doivent √™tre dans le dossier knowledge/ ou sp√©cifi√©s par chemin complet.",
        "tool": PDFSearchTool(),
        "enabled": True
    }
    
    tools["rag_tool"] = {
        "name": "RAG Tool (CrewAI)",
        "description": "Recherche dans base de connaissances via CrewAI. Utilise automatiquement les PDFs disponibles.",
        "tool": RagTool(),
        "enabled": True
    }
    
    return tools

def create_pdf_knowledge_sources(pdf_paths: List[str]) -> List:
    """Cr√©e des sources de connaissances PDF pour les agents"""
    knowledge_sources = []
    
    if not pdf_paths:
        print("Aucun PDF fourni pour les sources de connaissances")
        return knowledge_sources
    
    print(f"üìö Cr√©ation des sources de connaissances pour {len(pdf_paths)} PDF(s)")
    
    # Pour l'instant, on retourne une liste vide pour √©viter les erreurs de compatibilit√©
    # Les agents utiliseront directement les outils PDFSearchTool et RagTool
    print("üí° Les agents utiliseront les outils PDF natifs de CrewAI (PDFSearchTool, RagTool)")
    print("üìÑ PDFs disponibles pour les outils :")
    
    for pdf_path in pdf_paths:
        if os.path.exists(pdf_path):
            abs_path = os.path.abspath(pdf_path)
            print(f"   ‚úÖ {abs_path}")
        else:
            print(f"   ‚ö†Ô∏è Fichier non trouv√©: {pdf_path}")
    
    print("üéØ Les outils PDF sont pr√™ts √† √™tre utilis√©s par les agents")
    return knowledge_sources

def get_tools_for_agent(agent_name: str, enabled_tools: List[str]) -> List[Any]:
    """Retourne les outils activ√©s pour un agent sp√©cifique"""
    available_tools = get_available_tools()
    agent_tools = []
    
    for tool_name in enabled_tools:
        if tool_name in available_tools and available_tools[tool_name]["enabled"]:
            agent_tools.append(available_tools[tool_name]["tool"])
    
    return agent_tools

# Configuration par d√©faut des outils par agent
DEFAULT_AGENT_TOOLS = {
    "manager_agent": ["serper_search", "rag_tool"],
    "web_research_agent": ["serper_search", "website_search", "scrape_website"],
    "pdf_analysis_agent": ["pdf_search", "rag_tool"],
    "content_writer_agent": ["serper_search", "rag_tool"]
}